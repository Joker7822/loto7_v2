
*** Begin Patch
*** Update File: lottery_prediction.py
@@
 import traceback
@@
 from itertools import combinations
 import shutil
 import traceback
@@
 import subprocess
+
+# === ã‚¬ãƒäºˆæ¸¬ãƒ‡ã‚³ãƒ¼ãƒ€ï¼ˆå‘¨è¾ºåŒ– + ILP/ãƒ“ãƒ¼ãƒ æ¢ç´¢ï¼‰ ===
+try:
+    from gachi_decoder import (
+        build_marginals_from_sets,
+        compute_pair_pmi,
+        decode_topK_sets,
+    )
+    _HAS_GACHI = True
+except Exception as _e:
+    print("[WARN] gachi_decoder ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ:", _e)
+    _HAS_GACHI = False
@@
 class LotoPredictor:
@@
     def predict(self, latest_data, num_candidates=50):
@@
         except Exception as e:
             print(f"[ERROR] äºˆæ¸¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
             traceback.print_exc()
             return numbers_only, confidence_scores
-            
+
         def _stable_diverse_selection(numbers_only, confidence_scores, latest_data,
                                     k=30, lambda_div=0.6, temperature=0.35):
@@
             return selected

         try:
             numbers_only = _stable_diverse_selection(
                 numbers_only, confidence_scores, latest_data,
                 k=30, lambda_div=0.6, temperature=0.35
             )
             confidence_scores = confidence_scores[:len(numbers_only)]

         except Exception as e:
             print(f"[ERROR] äºˆæ¸¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
             traceback.print_exc()
             return numbers_only, confidence_scores
+
+        return numbers_only, confidence_scores
+
+    # === ğŸ†• ã‚¬ãƒäºˆæ¸¬: 7å€‹å½“ãŸã‚Šã‚’ç›®æŒ‡ã™æœ€é©åŒ–ãƒ‡ã‚³ãƒ¼ãƒ€ ===
+    def predict_gachi(self, latest_data, k_sets=10, alpha_pair=0.3):
+        """
+        1) æ—¢å­˜predictã§å¤šæ•°å€™è£œã‚’ç”Ÿæˆ â†’
+        2) å€™è£œã‹ã‚‰å‘¨è¾ºç¢ºç‡ã‚’æ¨å®šï¼ˆGNNç­‰ã®è¿½åŠ ãƒ­ã‚°itãŒã‚ã‚Œã°ä½µç”¨ï¼‰â†’
+        3) ILP/ãƒ“ãƒ¼ãƒ æ¢ç´¢ã§ç›®çš„é–¢æ•°æœ€å¤§ã¨ãªã‚‹ã‚»ãƒƒãƒˆã‚’ä¸Šä½kä»¶è¿”ã™
+        """
+        base = self.predict(latest_data, num_candidates=200)
+        if base is None or base[0] is None:
+            return None, None
+        candidates, conf = base
+
+        # å‘¨è¾ºç¢ºç‡
+        extra_logits = []
+        try:
+            # GNNã‚¹ã‚³ã‚¢ï¼ˆã‚ã‚Œã°è¿½åŠ ï¼‰
+            from gnn_core import build_cooccurrence_graph
+            graph_data = build_cooccurrence_graph(latest_data)
+            if hasattr(self, "gnn_model") and self.gnn_model is not None:
+                self.gnn_model.eval()
+                with torch.no_grad():
+                    gnn_scores = self.gnn_model(graph_data.x, graph_data.edge_index).squeeze().cpu().numpy()
+                extra_logits.append(gnn_scores)
+        except Exception as _e:
+            print("[INFO] GNNãƒ­ã‚°itã®å–å¾—ã‚’ã‚¹ã‚­ãƒƒãƒ—:", _e)
+
+        p = build_marginals_from_sets(candidates, conf, extra_logits=extra_logits)
+
+        # ãƒšã‚¢PMIï¼ˆå±¥æ­´ã‹ã‚‰ï¼‰
+        try:
+            hist = latest_data.copy()
+            pair_pmi = compute_pair_pmi(hist)
+        except Exception as _e:
+            print("[INFO] PMIè¨ˆç®—ã‚’ã‚¹ã‚­ãƒƒãƒ—:", _e)
+            pair_pmi = None
+
+        top = decode_topK_sets(p, pair_pmi, K=k_sets, alpha_pair=alpha_pair)
+        if not top:
+            return candidates[:k_sets], conf[:k_sets]
+
+        decoded, scores = zip(*top)
+        # ã‚¹ã‚³ã‚¢ã‚’[0,1]ã«æ­£è¦åŒ–ã—ã¦ä¿¡é ¼åº¦ã£ã½ã
+        s = np.array(scores, dtype=float)
+        s = (s - s.min()) / (s.max() - s.min() + 1e-9)
+        return list(decoded), list(s)
*** End Patch
