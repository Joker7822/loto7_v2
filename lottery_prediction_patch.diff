
*** Begin Patch
*** Update File: lottery_prediction.py
@@
 import traceback
@@
 from itertools import combinations
 import shutil
 import traceback
@@
 import subprocess
+
+# === ガチ予測デコーダ（周辺化 + ILP/ビーム探索） ===
+try:
+    from gachi_decoder import (
+        build_marginals_from_sets,
+        compute_pair_pmi,
+        decode_topK_sets,
+    )
+    _HAS_GACHI = True
+except Exception as _e:
+    print("[WARN] gachi_decoder の読み込みに失敗しました:", _e)
+    _HAS_GACHI = False
@@
 class LotoPredictor:
@@
     def predict(self, latest_data, num_candidates=50):
@@
         except Exception as e:
             print(f"[ERROR] 予測中にエラー発生: {e}")
             traceback.print_exc()
             return numbers_only, confidence_scores
-            
+
         def _stable_diverse_selection(numbers_only, confidence_scores, latest_data,
                                     k=30, lambda_div=0.6, temperature=0.35):
@@
             return selected

         try:
             numbers_only = _stable_diverse_selection(
                 numbers_only, confidence_scores, latest_data,
                 k=30, lambda_div=0.6, temperature=0.35
             )
             confidence_scores = confidence_scores[:len(numbers_only)]

         except Exception as e:
             print(f"[ERROR] 予測中にエラー発生: {e}")
             traceback.print_exc()
             return numbers_only, confidence_scores
+
+        return numbers_only, confidence_scores
+
+    # === 🆕 ガチ予測: 7個当たりを目指す最適化デコーダ ===
+    def predict_gachi(self, latest_data, k_sets=10, alpha_pair=0.3):
+        """
+        1) 既存predictで多数候補を生成 →
+        2) 候補から周辺確率を推定（GNN等の追加ログitがあれば併用）→
+        3) ILP/ビーム探索で目的関数最大となるセットを上位k件返す
+        """
+        base = self.predict(latest_data, num_candidates=200)
+        if base is None or base[0] is None:
+            return None, None
+        candidates, conf = base
+
+        # 周辺確率
+        extra_logits = []
+        try:
+            # GNNスコア（あれば追加）
+            from gnn_core import build_cooccurrence_graph
+            graph_data = build_cooccurrence_graph(latest_data)
+            if hasattr(self, "gnn_model") and self.gnn_model is not None:
+                self.gnn_model.eval()
+                with torch.no_grad():
+                    gnn_scores = self.gnn_model(graph_data.x, graph_data.edge_index).squeeze().cpu().numpy()
+                extra_logits.append(gnn_scores)
+        except Exception as _e:
+            print("[INFO] GNNログitの取得をスキップ:", _e)
+
+        p = build_marginals_from_sets(candidates, conf, extra_logits=extra_logits)
+
+        # ペアPMI（履歴から）
+        try:
+            hist = latest_data.copy()
+            pair_pmi = compute_pair_pmi(hist)
+        except Exception as _e:
+            print("[INFO] PMI計算をスキップ:", _e)
+            pair_pmi = None
+
+        top = decode_topK_sets(p, pair_pmi, K=k_sets, alpha_pair=alpha_pair)
+        if not top:
+            return candidates[:k_sets], conf[:k_sets]
+
+        decoded, scores = zip(*top)
+        # スコアを[0,1]に正規化して信頼度っぽく
+        s = np.array(scores, dtype=float)
+        s = (s - s.min()) / (s.max() - s.min() + 1e-9)
+        return list(decoded), list(s)
*** End Patch
